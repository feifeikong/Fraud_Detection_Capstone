{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fef1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4385f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d67abf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_age_days</th>\n",
       "      <th>transaction_amt</th>\n",
       "      <th>transaction_adj_amt</th>\n",
       "      <th>historic_velocity</th>\n",
       "      <th>days_since_last_logon</th>\n",
       "      <th>inital_amount</th>\n",
       "      <th>EVENT_LABEL</th>\n",
       "      <th>ip_counts</th>\n",
       "      <th>Currency_cad</th>\n",
       "      <th>Currency_eur</th>\n",
       "      <th>Currency_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3557.0</td>\n",
       "      <td>2196.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>10447.0</td>\n",
       "      <td>legit</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5454.0</td>\n",
       "      <td>3037.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6215.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6337.0</td>\n",
       "      <td>legit</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4685.0</td>\n",
       "      <td>3415.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6478.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>11032.0</td>\n",
       "      <td>legit</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2934.0</td>\n",
       "      <td>2613.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5475.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13205.0</td>\n",
       "      <td>legit</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4127.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>8346.0</td>\n",
       "      <td>legit</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_age_days  transaction_amt  transaction_adj_amt  historic_velocity  \\\n",
       "0            3557.0           2196.0                 62.0             4346.0   \n",
       "1            5454.0           3037.0                 54.0             6215.0   \n",
       "2            4685.0           3415.0                 43.0             6478.0   \n",
       "3            2934.0           2613.0                 56.0             5475.0   \n",
       "4            4127.0           1364.0                 62.0             2420.0   \n",
       "\n",
       "   days_since_last_logon  inital_amount EVENT_LABEL  ip_counts  Currency_cad  \\\n",
       "0                   68.0        10447.0       legit          1             1   \n",
       "1                   67.0         6337.0       legit          1             1   \n",
       "2                   91.0        11032.0       legit          1             1   \n",
       "3                   21.0        13205.0       legit          1             1   \n",
       "4                   91.0         8346.0       legit          1             1   \n",
       "\n",
       "   Currency_eur  Currency_usd  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             0             0  \n",
       "3             0             0  \n",
       "4             0             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "834ebefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   account_age_days       150000 non-null  float64\n",
      " 1   transaction_amt        150000 non-null  float64\n",
      " 2   transaction_adj_amt    150000 non-null  float64\n",
      " 3   historic_velocity      150000 non-null  float64\n",
      " 4   days_since_last_logon  150000 non-null  float64\n",
      " 5   inital_amount          150000 non-null  float64\n",
      " 6   EVENT_LABEL            150000 non-null  object \n",
      " 7   ip_counts              150000 non-null  int64  \n",
      " 8   Currency_cad           150000 non-null  int64  \n",
      " 9   Currency_eur           150000 non-null  int64  \n",
      " 10  Currency_usd           150000 non-null  int64  \n",
      "dtypes: float64(6), int64(4), object(1)\n",
      "memory usage: 12.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6e5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into features and target\n",
    "#target is mapped to numeric (0 for fraud, 1 for legit)\n",
    "\n",
    "X = data.drop('EVENT_LABEL', axis=1)\n",
    "y = data['EVENT_LABEL'].map({'legit': 1, 'fraud': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1120ce86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_age_days</th>\n",
       "      <th>transaction_amt</th>\n",
       "      <th>transaction_adj_amt</th>\n",
       "      <th>historic_velocity</th>\n",
       "      <th>days_since_last_logon</th>\n",
       "      <th>inital_amount</th>\n",
       "      <th>ip_counts</th>\n",
       "      <th>Currency_cad</th>\n",
       "      <th>Currency_eur</th>\n",
       "      <th>Currency_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4642.444247</td>\n",
       "      <td>2521.478480</td>\n",
       "      <td>54.203040</td>\n",
       "      <td>4702.221347</td>\n",
       "      <td>49.866513</td>\n",
       "      <td>7998.028667</td>\n",
       "      <td>8.824667</td>\n",
       "      <td>0.758340</td>\n",
       "      <td>0.029153</td>\n",
       "      <td>0.211787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1159.965133</td>\n",
       "      <td>604.262506</td>\n",
       "      <td>10.066597</td>\n",
       "      <td>1188.021280</td>\n",
       "      <td>29.191524</td>\n",
       "      <td>4045.344431</td>\n",
       "      <td>6.238538</td>\n",
       "      <td>0.428091</td>\n",
       "      <td>0.168237</td>\n",
       "      <td>0.408576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3821.000000</td>\n",
       "      <td>2104.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>3873.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4666.000000</td>\n",
       "      <td>2544.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>4730.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>8002.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5475.000000</td>\n",
       "      <td>2951.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>5548.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>11491.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9119.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       account_age_days  transaction_amt  transaction_adj_amt  \\\n",
       "count     150000.000000    150000.000000        150000.000000   \n",
       "mean        4642.444247      2521.478480            54.203040   \n",
       "std         1159.965133       604.262506            10.066597   \n",
       "min            1.000000         5.000000             1.000000   \n",
       "25%         3821.000000      2104.000000            48.000000   \n",
       "50%         4666.000000      2544.000000            55.000000   \n",
       "75%         5475.000000      2951.000000            61.000000   \n",
       "max         9119.000000      4999.000000            99.000000   \n",
       "\n",
       "       historic_velocity  days_since_last_logon  inital_amount      ip_counts  \\\n",
       "count      150000.000000          150000.000000  150000.000000  150000.000000   \n",
       "mean         4702.221347              49.866513    7998.028667       8.824667   \n",
       "std          1188.021280              29.191524    4045.344431       6.238538   \n",
       "min            50.000000               0.000000    1000.000000       0.000000   \n",
       "25%          3873.000000              25.000000    4491.000000       4.000000   \n",
       "50%          4730.000000              50.000000    8002.000000       8.000000   \n",
       "75%          5548.000000              75.000000   11491.000000      13.000000   \n",
       "max          9999.000000             100.000000   15000.000000      37.000000   \n",
       "\n",
       "        Currency_cad   Currency_eur   Currency_usd  \n",
       "count  150000.000000  150000.000000  150000.000000  \n",
       "mean        0.758340       0.029153       0.211787  \n",
       "std         0.428091       0.168237       0.408576  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         1.000000       0.000000       0.000000  \n",
       "50%         1.000000       0.000000       0.000000  \n",
       "75%         1.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832186c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de904fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize features to have same range\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff7ce2",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e858f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a classification problem\n",
    "#try logistic regression, random forest / gradient boosting, and XG boost\n",
    "#grid search CV on hyperparameters\n",
    "#tree models: try both max_depth and min_samples_leaf hyperparameters\n",
    "#neural network: grab templates online to use -- evaluate performance compared to trees (not as good for imbalanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7cb4046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1715c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning for GB model\n",
    "\n",
    "params = {'max_depth': [3, 10, 1000], 'min_samples_leaf': [1, 50, 100], 'n_iter_no_change': [5]}\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), params, cv=5)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "gb_params = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f786986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning for Random Forest model\n",
    "\n",
    "params = {'max_depth': [3, 10, 15], 'min_samples_leaf': [1, 50, 100], 'n_estimators': [100]}\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), params, cv=5)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "rf_params = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6ec8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning for XGBoost model\n",
    "\n",
    "params = {'max_depth': [3, 6, 10], 'min_child_weight': [1, 50, 100], 'n_estimators': [100]}\n",
    "\n",
    "clf = GridSearchCV(XGBClassifier(use_label_encoder=False), params, cv=5)\n",
    "clf.fit(X_train_scaled, y_train, eval_metric='auc')\n",
    "xgb_params = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d1d2280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:05:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#create dictionary containing all of the models\n",
    "#write a function that fits and predicts on all of the models in the dictionary and saves the \n",
    "#predicted values into a dataframe and the auc into a dictionary\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "models = {'rf': RandomForestClassifier(**rf_params), \n",
    "          'gbm': GradientBoostingClassifier(**gb_params),\n",
    "          'lr': LogisticRegression(),\n",
    "          'xgb': XGBClassifier(**xgb_params)}\n",
    "\n",
    "pred_probas = pd.DataFrame()\n",
    "auc_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    local_model = model.fit(X_train_scaled, y_train)\n",
    "    y_pred_proba = local_model.predict_proba(X_test_scaled)\n",
    "    pred_probas[name] = y_pred_proba[:,1]\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "    auc_scores[name] = auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1294db75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf': 0.9250944052393312,\n",
       " 'gbm': 0.9274213064806659,\n",
       " 'lr': 0.91381486034911,\n",
       " 'xgb': 0.9283315545543623}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ad41788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost model is the best performing with auc = 0.928 as an evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73ae53ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find roc for xgb model\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresh = roc_curve(y_test, pred_probas['xgb'], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n",
    "\n",
    "#plot roc curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curve\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange', label='XGBoost Classifier')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1376632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try neural network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "123c8fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1h/f10mrm6x3sg309bl17kg39r40000gp/T/ipykernel_57267/2346083325.py:13: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=500, verbose=1)\n",
      "2022-01-26 16:30:23.557016: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "216/216 [==============================] - 1s 1ms/step - loss: 0.3530 - accuracy: 0.9144\n",
      "Epoch 2/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9515\n",
      "Epoch 3/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9575\n",
      "Epoch 4/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 0.9606\n",
      "Epoch 5/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9621\n",
      "Epoch 6/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9628\n",
      "Epoch 7/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9633\n",
      "Epoch 8/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.9634\n",
      "Epoch 9/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9637\n",
      "Epoch 10/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9638\n",
      "Epoch 11/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9639\n",
      "Epoch 12/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9641\n",
      "Epoch 13/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9642\n",
      "Epoch 14/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9645\n",
      "Epoch 15/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9644\n",
      "Epoch 16/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9647\n",
      "Epoch 17/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9650\n",
      "Epoch 18/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9650\n",
      "Epoch 19/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9654\n",
      "Epoch 20/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9655\n",
      "Epoch 21/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9653\n",
      "Epoch 22/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9656\n",
      "Epoch 23/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9657\n",
      "Epoch 24/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9659\n",
      "Epoch 25/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9659\n",
      "Epoch 26/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9659\n",
      "Epoch 27/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9661\n",
      "Epoch 28/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9660\n",
      "Epoch 29/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9662\n",
      "Epoch 30/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9662\n",
      "Epoch 31/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9663\n",
      "Epoch 32/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9665\n",
      "Epoch 33/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9663\n",
      "Epoch 34/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9663\n",
      "Epoch 35/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9663\n",
      "Epoch 36/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.9664\n",
      "Epoch 37/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9665\n",
      "Epoch 38/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9664\n",
      "Epoch 39/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9664\n",
      "Epoch 40/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9666\n",
      "Epoch 41/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9665\n",
      "Epoch 42/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9665\n",
      "Epoch 43/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.9665\n",
      "Epoch 44/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9665\n",
      "Epoch 45/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9665\n",
      "Epoch 46/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9665\n",
      "Epoch 47/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9665\n",
      "Epoch 48/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9665\n",
      "Epoch 49/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9665\n",
      "Epoch 50/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9666\n",
      "Epoch 51/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 52/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9664\n",
      "Epoch 53/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9666\n",
      "Epoch 54/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9666\n",
      "Epoch 55/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9666\n",
      "Epoch 56/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9666\n",
      "Epoch 57/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9665\n",
      "Epoch 58/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9665\n",
      "Epoch 59/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9667\n",
      "Epoch 60/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9666\n",
      "Epoch 61/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 62/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9667\n",
      "Epoch 63/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9668\n",
      "Epoch 64/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9668\n",
      "Epoch 65/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9668\n",
      "Epoch 66/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9668\n",
      "Epoch 67/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9669\n",
      "Epoch 68/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9669\n",
      "Epoch 69/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9669\n",
      "Epoch 70/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9669\n",
      "Epoch 71/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9668\n",
      "Epoch 72/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9668\n",
      "Epoch 73/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9669\n",
      "Epoch 74/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9668\n",
      "Epoch 75/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9668\n",
      "Epoch 76/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9669\n",
      "Epoch 77/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 78/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 79/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9668\n",
      "Epoch 80/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9667\n",
      "Epoch 81/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 82/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9669\n",
      "Epoch 83/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9669\n",
      "Epoch 84/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9668\n",
      "Epoch 85/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9669\n",
      "Epoch 86/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9669\n",
      "Epoch 87/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9670\n",
      "Epoch 88/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9670\n",
      "Epoch 89/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9671\n",
      "Epoch 90/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9670\n",
      "Epoch 91/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9668\n",
      "Epoch 92/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9669\n",
      "Epoch 93/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9669\n",
      "Epoch 94/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9669\n",
      "Epoch 95/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9669\n",
      "Epoch 96/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9670\n",
      "Epoch 97/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9670\n",
      "Epoch 98/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9669\n",
      "Epoch 99/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9670\n",
      "Epoch 100/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9668\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9663\n",
      "Epoch 1/100\n",
      "216/216 [==============================] - 1s 1ms/step - loss: 0.4710 - accuracy: 0.7958\n",
      "Epoch 2/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9496\n",
      "Epoch 3/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9551\n",
      "Epoch 4/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9583\n",
      "Epoch 5/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9605\n",
      "Epoch 6/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9615\n",
      "Epoch 7/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9622\n",
      "Epoch 8/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9627\n",
      "Epoch 9/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9629\n",
      "Epoch 10/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9631\n",
      "Epoch 11/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9633\n",
      "Epoch 12/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1133 - accuracy: 0.9636\n",
      "Epoch 13/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.9638\n",
      "Epoch 14/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1121 - accuracy: 0.9640\n",
      "Epoch 15/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.9643\n",
      "Epoch 16/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9646\n",
      "Epoch 17/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9646\n",
      "Epoch 18/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9649\n",
      "Epoch 19/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9649\n",
      "Epoch 20/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9652\n",
      "Epoch 21/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9653\n",
      "Epoch 22/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9653\n",
      "Epoch 23/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9654\n",
      "Epoch 24/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9653\n",
      "Epoch 25/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9654\n",
      "Epoch 26/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9656\n",
      "Epoch 27/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9654\n",
      "Epoch 28/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9655\n",
      "Epoch 29/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9656\n",
      "Epoch 30/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9658\n",
      "Epoch 31/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9655\n",
      "Epoch 32/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9657\n",
      "Epoch 33/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9658\n",
      "Epoch 34/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9658\n",
      "Epoch 35/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9659\n",
      "Epoch 36/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9659\n",
      "Epoch 37/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9659\n",
      "Epoch 38/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9658\n",
      "Epoch 39/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9660\n",
      "Epoch 40/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9661\n",
      "Epoch 41/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9660\n",
      "Epoch 42/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9661\n",
      "Epoch 43/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9660\n",
      "Epoch 44/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9660\n",
      "Epoch 45/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9662\n",
      "Epoch 46/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9661\n",
      "Epoch 47/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9662\n",
      "Epoch 48/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9661\n",
      "Epoch 49/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9661\n",
      "Epoch 50/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9662\n",
      "Epoch 51/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9662\n",
      "Epoch 52/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9663\n",
      "Epoch 53/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9663\n",
      "Epoch 54/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9663\n",
      "Epoch 55/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9661\n",
      "Epoch 56/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9663\n",
      "Epoch 57/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9664\n",
      "Epoch 58/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9663\n",
      "Epoch 59/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9663\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9663\n",
      "Epoch 61/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9663\n",
      "Epoch 62/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9663\n",
      "Epoch 63/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9662\n",
      "Epoch 64/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9664\n",
      "Epoch 65/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9663\n",
      "Epoch 66/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9663\n",
      "Epoch 67/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9664\n",
      "Epoch 68/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9663\n",
      "Epoch 69/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9663\n",
      "Epoch 70/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9664\n",
      "Epoch 71/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9665\n",
      "Epoch 72/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9665\n",
      "Epoch 73/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9663\n",
      "Epoch 74/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9664\n",
      "Epoch 75/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9663\n",
      "Epoch 76/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9664\n",
      "Epoch 77/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9663\n",
      "Epoch 78/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9662\n",
      "Epoch 79/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9663\n",
      "Epoch 80/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9664\n",
      "Epoch 81/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9663\n",
      "Epoch 82/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9664\n",
      "Epoch 83/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9665\n",
      "Epoch 84/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9664\n",
      "Epoch 85/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9664\n",
      "Epoch 86/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9665\n",
      "Epoch 87/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9666\n",
      "Epoch 88/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9665\n",
      "Epoch 89/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9666\n",
      "Epoch 90/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9664\n",
      "Epoch 91/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9664\n",
      "Epoch 92/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9663\n",
      "Epoch 93/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 94/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 95/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 96/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9664\n",
      "Epoch 97/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9664\n",
      "Epoch 98/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9665\n",
      "Epoch 99/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9666\n",
      "Epoch 100/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9664\n",
      "24/24 [==============================] - 0s 993us/step - loss: 0.0963 - accuracy: 0.9702\n",
      "Epoch 1/100\n",
      "216/216 [==============================] - 1s 1ms/step - loss: 0.3263 - accuracy: 0.8802\n",
      "Epoch 2/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9456\n",
      "Epoch 3/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9459\n",
      "Epoch 4/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9468\n",
      "Epoch 5/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1297 - accuracy: 0.9532\n",
      "Epoch 6/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9598\n",
      "Epoch 7/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9624\n",
      "Epoch 8/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9634\n",
      "Epoch 9/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9637\n",
      "Epoch 10/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9641\n",
      "Epoch 11/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.9645\n",
      "Epoch 12/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9645\n",
      "Epoch 13/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9648\n",
      "Epoch 14/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9649\n",
      "Epoch 15/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9649\n",
      "Epoch 16/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9653\n",
      "Epoch 17/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9654\n",
      "Epoch 18/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9657\n",
      "Epoch 19/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9657\n",
      "Epoch 20/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9658\n",
      "Epoch 21/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9658\n",
      "Epoch 22/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9661\n",
      "Epoch 23/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9662\n",
      "Epoch 24/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9661\n",
      "Epoch 25/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9663\n",
      "Epoch 26/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9663\n",
      "Epoch 27/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9662\n",
      "Epoch 28/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9664\n",
      "Epoch 29/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9663\n",
      "Epoch 30/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9664\n",
      "Epoch 31/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9665\n",
      "Epoch 32/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9665\n",
      "Epoch 33/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9665\n",
      "Epoch 34/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9667\n",
      "Epoch 35/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9665\n",
      "Epoch 36/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9665\n",
      "Epoch 37/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9666\n",
      "Epoch 38/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9666\n",
      "Epoch 39/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9666\n",
      "Epoch 40/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9667\n",
      "Epoch 41/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9668\n",
      "Epoch 42/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9666\n",
      "Epoch 43/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9666\n",
      "Epoch 44/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9666\n",
      "Epoch 45/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9668\n",
      "Epoch 46/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9666\n",
      "Epoch 47/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9667\n",
      "Epoch 48/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9666\n",
      "Epoch 49/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9667\n",
      "Epoch 50/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9667\n",
      "Epoch 51/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9667\n",
      "Epoch 52/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9666\n",
      "Epoch 53/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 54/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9667\n",
      "Epoch 55/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.9666\n",
      "Epoch 56/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 57/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9667\n",
      "Epoch 58/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9666\n",
      "Epoch 59/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9666\n",
      "Epoch 60/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9666\n",
      "Epoch 61/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9666\n",
      "Epoch 62/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 63/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 64/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9666\n",
      "Epoch 65/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 66/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 67/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9667\n",
      "Epoch 68/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9666\n",
      "Epoch 69/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9667\n",
      "Epoch 70/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9668\n",
      "Epoch 71/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9667\n",
      "Epoch 72/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9669\n",
      "Epoch 73/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9668\n",
      "Epoch 74/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9666\n",
      "Epoch 75/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9669\n",
      "Epoch 76/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9667\n",
      "Epoch 77/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9668\n",
      "Epoch 78/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9669\n",
      "Epoch 79/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9667\n",
      "Epoch 80/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9669\n",
      "Epoch 81/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9668\n",
      "Epoch 82/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9669\n",
      "Epoch 83/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9668\n",
      "Epoch 84/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9668\n",
      "Epoch 85/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9669\n",
      "Epoch 86/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9669\n",
      "Epoch 87/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9668\n",
      "Epoch 88/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9668\n",
      "Epoch 89/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9669\n",
      "Epoch 90/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9667\n",
      "Epoch 91/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9669\n",
      "Epoch 92/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9669\n",
      "Epoch 93/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9669\n",
      "Epoch 94/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9669\n",
      "Epoch 95/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9669\n",
      "Epoch 96/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9668\n",
      "Epoch 97/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9669\n",
      "Epoch 98/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9668\n",
      "Epoch 99/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9669\n",
      "Epoch 100/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9669\n",
      "24/24 [==============================] - 0s 862us/step - loss: 0.1063 - accuracy: 0.9663\n",
      "Epoch 1/100\n",
      "216/216 [==============================] - 1s 1ms/step - loss: 0.5518 - accuracy: 0.7603\n",
      "Epoch 2/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.9418\n",
      "Epoch 3/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9467\n",
      "Epoch 4/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9523\n",
      "Epoch 5/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9581\n",
      "Epoch 6/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9608\n",
      "Epoch 7/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9620\n",
      "Epoch 8/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9627\n",
      "Epoch 9/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9632\n",
      "Epoch 10/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9637\n",
      "Epoch 11/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9637\n",
      "Epoch 12/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9640\n",
      "Epoch 13/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9642\n",
      "Epoch 14/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9645\n",
      "Epoch 15/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9645\n",
      "Epoch 16/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9648\n",
      "Epoch 17/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9650\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9649\n",
      "Epoch 19/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9652\n",
      "Epoch 20/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9653\n",
      "Epoch 21/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9655\n",
      "Epoch 22/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9657\n",
      "Epoch 23/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9660\n",
      "Epoch 24/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9660\n",
      "Epoch 25/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9662\n",
      "Epoch 26/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9662\n",
      "Epoch 27/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9662\n",
      "Epoch 28/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9665\n",
      "Epoch 29/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9664\n",
      "Epoch 30/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9665\n",
      "Epoch 31/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9666\n",
      "Epoch 32/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9664\n",
      "Epoch 33/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9666\n",
      "Epoch 34/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9664\n",
      "Epoch 35/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9665\n",
      "Epoch 36/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9666\n",
      "Epoch 37/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9665\n",
      "Epoch 38/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9665\n",
      "Epoch 39/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9666\n",
      "Epoch 40/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9667\n",
      "Epoch 41/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9667\n",
      "Epoch 42/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9665\n",
      "Epoch 43/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9665\n",
      "Epoch 44/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9666\n",
      "Epoch 45/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9667\n",
      "Epoch 46/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9667\n",
      "Epoch 47/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9667\n",
      "Epoch 48/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9668\n",
      "Epoch 49/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9666\n",
      "Epoch 50/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9667\n",
      "Epoch 51/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 52/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 53/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9668\n",
      "Epoch 54/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9668\n",
      "Epoch 55/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9666\n",
      "Epoch 56/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9668\n",
      "Epoch 57/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9668\n",
      "Epoch 58/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9666\n",
      "Epoch 59/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9668\n",
      "Epoch 60/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 61/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9668\n",
      "Epoch 62/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9668\n",
      "Epoch 63/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9669\n",
      "Epoch 64/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9669\n",
      "Epoch 65/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9668\n",
      "Epoch 66/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9669\n",
      "Epoch 67/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9670\n",
      "Epoch 68/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9669\n",
      "Epoch 69/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9670\n",
      "Epoch 70/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9668\n",
      "Epoch 71/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9670\n",
      "Epoch 72/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9670\n",
      "Epoch 73/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9670\n",
      "Epoch 74/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9669\n",
      "Epoch 75/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9668\n",
      "Epoch 76/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9669\n",
      "Epoch 77/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9669\n",
      "Epoch 78/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9670\n",
      "Epoch 79/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9670\n",
      "Epoch 80/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 81/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 82/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 83/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9669\n",
      "Epoch 84/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9671\n",
      "Epoch 85/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 86/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 87/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9671\n",
      "Epoch 88/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 89/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9671\n",
      "Epoch 90/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9670\n",
      "Epoch 91/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9670\n",
      "Epoch 92/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9671\n",
      "Epoch 93/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9670\n",
      "Epoch 94/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9671\n",
      "Epoch 95/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9671\n",
      "Epoch 96/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9671\n",
      "Epoch 97/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9670\n",
      "Epoch 98/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9671\n",
      "Epoch 99/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9670\n",
      "Epoch 100/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9670\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9669\n",
      "Epoch 1/100\n",
      "216/216 [==============================] - 1s 1ms/step - loss: 0.2977 - accuracy: 0.9228\n",
      "Epoch 2/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9504\n",
      "Epoch 3/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9558\n",
      "Epoch 4/100\n",
      "216/216 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9596\n",
      "Epoch 5/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9615\n",
      "Epoch 6/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9626\n",
      "Epoch 7/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9629\n",
      "Epoch 8/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9631\n",
      "Epoch 9/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9636\n",
      "Epoch 10/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9635\n",
      "Epoch 11/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9639\n",
      "Epoch 12/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1121 - accuracy: 0.9641\n",
      "Epoch 13/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.9643\n",
      "Epoch 14/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9644\n",
      "Epoch 15/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9645\n",
      "Epoch 16/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9648\n",
      "Epoch 17/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9647\n",
      "Epoch 18/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9649\n",
      "Epoch 19/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9649\n",
      "Epoch 20/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9650\n",
      "Epoch 21/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9652\n",
      "Epoch 22/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9652\n",
      "Epoch 23/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9658\n",
      "Epoch 24/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9659\n",
      "Epoch 25/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9660\n",
      "Epoch 26/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9660\n",
      "Epoch 27/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9662\n",
      "Epoch 28/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9662\n",
      "Epoch 29/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9662\n",
      "Epoch 30/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9664\n",
      "Epoch 31/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9664\n",
      "Epoch 32/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9666\n",
      "Epoch 33/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9666\n",
      "Epoch 34/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9666\n",
      "Epoch 35/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9667\n",
      "Epoch 36/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9667\n",
      "Epoch 37/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9668\n",
      "Epoch 38/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9669\n",
      "Epoch 39/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 40/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9669\n",
      "Epoch 41/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 42/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 43/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9669\n",
      "Epoch 44/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9669\n",
      "Epoch 45/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9669\n",
      "Epoch 46/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9671\n",
      "Epoch 47/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9668\n",
      "Epoch 48/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9669\n",
      "Epoch 49/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9670\n",
      "Epoch 50/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9670\n",
      "Epoch 51/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9669\n",
      "Epoch 52/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9671\n",
      "Epoch 53/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 54/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9670\n",
      "Epoch 55/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9671\n",
      "Epoch 56/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9670\n",
      "Epoch 57/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9671\n",
      "Epoch 58/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9670\n",
      "Epoch 59/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1050 - accuracy: 0.9672\n",
      "Epoch 60/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9670\n",
      "Epoch 61/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9672\n",
      "Epoch 62/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9670\n",
      "Epoch 63/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9671\n",
      "Epoch 64/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9671\n",
      "Epoch 65/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9671\n",
      "Epoch 66/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9671\n",
      "Epoch 67/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9672\n",
      "Epoch 68/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9671\n",
      "Epoch 69/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9671\n",
      "Epoch 70/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9672\n",
      "Epoch 71/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9672\n",
      "Epoch 72/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9672\n",
      "Epoch 73/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9671\n",
      "Epoch 74/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9671\n",
      "Epoch 75/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9671\n",
      "Epoch 76/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9672\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9673\n",
      "Epoch 78/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9674\n",
      "Epoch 79/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9672\n",
      "Epoch 80/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9672\n",
      "Epoch 81/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9673\n",
      "Epoch 82/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9671\n",
      "Epoch 83/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9673\n",
      "Epoch 84/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9672\n",
      "Epoch 85/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9672\n",
      "Epoch 86/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9673\n",
      "Epoch 87/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9671\n",
      "Epoch 88/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9673\n",
      "Epoch 89/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9673\n",
      "Epoch 90/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9672\n",
      "Epoch 91/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9672\n",
      "Epoch 92/100\n",
      "216/216 [==============================] - 0s 922us/step - loss: 0.1046 - accuracy: 0.9672\n",
      "Epoch 93/100\n",
      "216/216 [==============================] - 0s 962us/step - loss: 0.1046 - accuracy: 0.9672\n",
      "Epoch 94/100\n",
      "216/216 [==============================] - 0s 925us/step - loss: 0.1046 - accuracy: 0.9672\n",
      "Epoch 95/100\n",
      "216/216 [==============================] - 0s 926us/step - loss: 0.1046 - accuracy: 0.9672\n",
      "Epoch 96/100\n",
      "216/216 [==============================] - 0s 882us/step - loss: 0.1046 - accuracy: 0.9671\n",
      "Epoch 97/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9672\n",
      "Epoch 98/100\n",
      "216/216 [==============================] - 0s 898us/step - loss: 0.1046 - accuracy: 0.9673\n",
      "Epoch 99/100\n",
      "216/216 [==============================] - 0s 890us/step - loss: 0.1046 - accuracy: 0.9671\n",
      "Epoch 100/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9672\n",
      "24/24 [==============================] - 0s 719us/step - loss: 0.1111 - accuracy: 0.9646\n",
      "Epoch 1/100\n",
      "216/216 [==============================] - 0s 737us/step - loss: 0.3000 - accuracy: 0.9007\n",
      "Epoch 2/100\n",
      "216/216 [==============================] - 0s 780us/step - loss: 0.1596 - accuracy: 0.9520\n",
      "Epoch 3/100\n",
      "216/216 [==============================] - 0s 734us/step - loss: 0.1322 - accuracy: 0.9576\n",
      "Epoch 4/100\n",
      "216/216 [==============================] - 0s 802us/step - loss: 0.1232 - accuracy: 0.9605\n",
      "Epoch 5/100\n",
      "216/216 [==============================] - 0s 832us/step - loss: 0.1192 - accuracy: 0.9617\n",
      "Epoch 6/100\n",
      "216/216 [==============================] - 0s 774us/step - loss: 0.1169 - accuracy: 0.9626\n",
      "Epoch 7/100\n",
      "216/216 [==============================] - 0s 796us/step - loss: 0.1153 - accuracy: 0.9632\n",
      "Epoch 8/100\n",
      "216/216 [==============================] - 0s 828us/step - loss: 0.1139 - accuracy: 0.9637\n",
      "Epoch 9/100\n",
      "216/216 [==============================] - 0s 759us/step - loss: 0.1127 - accuracy: 0.9641\n",
      "Epoch 10/100\n",
      "216/216 [==============================] - 0s 752us/step - loss: 0.1118 - accuracy: 0.9644\n",
      "Epoch 11/100\n",
      "216/216 [==============================] - 0s 788us/step - loss: 0.1111 - accuracy: 0.9647\n",
      "Epoch 12/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1105 - accuracy: 0.9650\n",
      "Epoch 13/100\n",
      "216/216 [==============================] - 0s 818us/step - loss: 0.1101 - accuracy: 0.9651\n",
      "Epoch 14/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1097 - accuracy: 0.9652\n",
      "Epoch 15/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1093 - accuracy: 0.9653\n",
      "Epoch 16/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1090 - accuracy: 0.9656\n",
      "Epoch 17/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1088 - accuracy: 0.9656\n",
      "Epoch 18/100\n",
      "216/216 [==============================] - 0s 734us/step - loss: 0.1085 - accuracy: 0.9656\n",
      "Epoch 19/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1083 - accuracy: 0.9657\n",
      "Epoch 20/100\n",
      "216/216 [==============================] - 0s 821us/step - loss: 0.1082 - accuracy: 0.9658\n",
      "Epoch 21/100\n",
      "216/216 [==============================] - 0s 800us/step - loss: 0.1080 - accuracy: 0.9659\n",
      "Epoch 22/100\n",
      "216/216 [==============================] - 0s 799us/step - loss: 0.1078 - accuracy: 0.9658\n",
      "Epoch 23/100\n",
      "216/216 [==============================] - 0s 751us/step - loss: 0.1076 - accuracy: 0.9660\n",
      "Epoch 24/100\n",
      "216/216 [==============================] - 0s 812us/step - loss: 0.1075 - accuracy: 0.9660\n",
      "Epoch 25/100\n",
      "216/216 [==============================] - 0s 793us/step - loss: 0.1074 - accuracy: 0.9661\n",
      "Epoch 26/100\n",
      "216/216 [==============================] - 0s 894us/step - loss: 0.1073 - accuracy: 0.9660\n",
      "Epoch 27/100\n",
      "216/216 [==============================] - 0s 818us/step - loss: 0.1072 - accuracy: 0.9661\n",
      "Epoch 28/100\n",
      "216/216 [==============================] - 0s 738us/step - loss: 0.1070 - accuracy: 0.9661\n",
      "Epoch 29/100\n",
      "216/216 [==============================] - 0s 801us/step - loss: 0.1070 - accuracy: 0.9661\n",
      "Epoch 30/100\n",
      "216/216 [==============================] - 0s 776us/step - loss: 0.1069 - accuracy: 0.9661\n",
      "Epoch 31/100\n",
      "216/216 [==============================] - 0s 816us/step - loss: 0.1067 - accuracy: 0.9662\n",
      "Epoch 32/100\n",
      "216/216 [==============================] - 0s 746us/step - loss: 0.1067 - accuracy: 0.9663\n",
      "Epoch 33/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1066 - accuracy: 0.9664\n",
      "Epoch 34/100\n",
      "216/216 [==============================] - 0s 707us/step - loss: 0.1065 - accuracy: 0.9664\n",
      "Epoch 35/100\n",
      "216/216 [==============================] - 0s 702us/step - loss: 0.1064 - accuracy: 0.9664\n",
      "Epoch 36/100\n",
      "216/216 [==============================] - 0s 739us/step - loss: 0.1065 - accuracy: 0.9665\n",
      "Epoch 37/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1064 - accuracy: 0.9665\n",
      "Epoch 38/100\n",
      "216/216 [==============================] - 0s 794us/step - loss: 0.1063 - accuracy: 0.9665\n",
      "Epoch 39/100\n",
      "216/216 [==============================] - 0s 751us/step - loss: 0.1063 - accuracy: 0.9667\n",
      "Epoch 40/100\n",
      "216/216 [==============================] - 0s 765us/step - loss: 0.1063 - accuracy: 0.9665\n",
      "Epoch 41/100\n",
      "216/216 [==============================] - 0s 742us/step - loss: 0.1063 - accuracy: 0.9665\n",
      "Epoch 42/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1062 - accuracy: 0.9665\n",
      "Epoch 43/100\n",
      "216/216 [==============================] - 0s 743us/step - loss: 0.1062 - accuracy: 0.9665\n",
      "Epoch 44/100\n",
      "216/216 [==============================] - 0s 745us/step - loss: 0.1061 - accuracy: 0.9666\n",
      "Epoch 45/100\n",
      "216/216 [==============================] - 0s 711us/step - loss: 0.1062 - accuracy: 0.9665\n",
      "Epoch 46/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1061 - accuracy: 0.9664\n",
      "Epoch 47/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1061 - accuracy: 0.9666\n",
      "Epoch 48/100\n",
      "216/216 [==============================] - 0s 772us/step - loss: 0.1060 - accuracy: 0.9667\n",
      "Epoch 49/100\n",
      "216/216 [==============================] - 0s 773us/step - loss: 0.1060 - accuracy: 0.9666\n",
      "Epoch 50/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.1060 - accuracy: 0.9663\n",
      "Epoch 51/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1060 - accuracy: 0.9667\n",
      "Epoch 52/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1060 - accuracy: 0.9666\n",
      "Epoch 53/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1060 - accuracy: 0.9665\n",
      "Epoch 54/100\n",
      "216/216 [==============================] - 0s 741us/step - loss: 0.1059 - accuracy: 0.9668\n",
      "Epoch 55/100\n",
      "216/216 [==============================] - 0s 776us/step - loss: 0.1060 - accuracy: 0.9666\n",
      "Epoch 56/100\n",
      "216/216 [==============================] - 0s 742us/step - loss: 0.1059 - accuracy: 0.9666\n",
      "Epoch 57/100\n",
      "216/216 [==============================] - 0s 764us/step - loss: 0.1059 - accuracy: 0.9666\n",
      "Epoch 58/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1059 - accuracy: 0.9668\n",
      "Epoch 59/100\n",
      "216/216 [==============================] - 0s 736us/step - loss: 0.1059 - accuracy: 0.9666\n",
      "Epoch 60/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1059 - accuracy: 0.9667\n",
      "Epoch 61/100\n",
      "216/216 [==============================] - 0s 741us/step - loss: 0.1059 - accuracy: 0.9669\n",
      "Epoch 62/100\n",
      "216/216 [==============================] - 0s 784us/step - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 63/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1058 - accuracy: 0.9668\n",
      "Epoch 64/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1058 - accuracy: 0.9669\n",
      "Epoch 65/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 66/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1058 - accuracy: 0.9668\n",
      "Epoch 67/100\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.1057 - accuracy: 0.9667\n",
      "Epoch 68/100\n",
      "216/216 [==============================] - 0s 752us/step - loss: 0.1058 - accuracy: 0.9668\n",
      "Epoch 69/100\n",
      "216/216 [==============================] - 0s 749us/step - loss: 0.1058 - accuracy: 0.9668\n",
      "Epoch 70/100\n",
      "216/216 [==============================] - 0s 757us/step - loss: 0.1058 - accuracy: 0.9667\n",
      "Epoch 71/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1057 - accuracy: 0.9667\n",
      "Epoch 72/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1057 - accuracy: 0.9667\n",
      "Epoch 73/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1057 - accuracy: 0.9668\n",
      "Epoch 74/100\n",
      "216/216 [==============================] - 0s 734us/step - loss: 0.1057 - accuracy: 0.9668\n",
      "Epoch 75/100\n",
      "216/216 [==============================] - 0s 756us/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 76/100\n",
      "216/216 [==============================] - 0s 736us/step - loss: 0.1056 - accuracy: 0.9669\n",
      "Epoch 77/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 78/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1056 - accuracy: 0.9668\n",
      "Epoch 79/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1056 - accuracy: 0.9668\n",
      "Epoch 80/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.1055 - accuracy: 0.9665\n",
      "Epoch 81/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1055 - accuracy: 0.9669\n",
      "Epoch 82/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1055 - accuracy: 0.9669\n",
      "Epoch 83/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1055 - accuracy: 0.9669\n",
      "Epoch 84/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.1055 - accuracy: 0.9670\n",
      "Epoch 85/100\n",
      "216/216 [==============================] - 0s 731us/step - loss: 0.1055 - accuracy: 0.9670\n",
      "Epoch 86/100\n",
      "216/216 [==============================] - 0s 743us/step - loss: 0.1054 - accuracy: 0.9668\n",
      "Epoch 87/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1054 - accuracy: 0.9670\n",
      "Epoch 88/100\n",
      "216/216 [==============================] - 0s 731us/step - loss: 0.1054 - accuracy: 0.9667\n",
      "Epoch 89/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1054 - accuracy: 0.9669\n",
      "Epoch 90/100\n",
      "216/216 [==============================] - 0s 736us/step - loss: 0.1054 - accuracy: 0.9670\n",
      "Epoch 91/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1054 - accuracy: 0.9670\n",
      "Epoch 92/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1053 - accuracy: 0.9668\n",
      "Epoch 93/100\n",
      "216/216 [==============================] - 0s 757us/step - loss: 0.1054 - accuracy: 0.9669\n",
      "Epoch 94/100\n",
      "216/216 [==============================] - 0s 740us/step - loss: 0.1053 - accuracy: 0.9669\n",
      "Epoch 95/100\n",
      "216/216 [==============================] - 0s 721us/step - loss: 0.1053 - accuracy: 0.9668\n",
      "Epoch 96/100\n",
      "216/216 [==============================] - 0s 742us/step - loss: 0.1053 - accuracy: 0.9669\n",
      "Epoch 97/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1052 - accuracy: 0.9670\n",
      "Epoch 98/100\n",
      "216/216 [==============================] - 0s 741us/step - loss: 0.1052 - accuracy: 0.9670\n",
      "Epoch 99/100\n",
      "216/216 [==============================] - 0s 922us/step - loss: 0.1052 - accuracy: 0.9670\n",
      "Epoch 100/100\n",
      "216/216 [==============================] - 0s 812us/step - loss: 0.1052 - accuracy: 0.9670\n",
      "24/24 [==============================] - 0s 698us/step - loss: 0.1041 - accuracy: 0.9671\n",
      "Epoch 1/100\n",
      "216/216 [==============================] - 0s 915us/step - loss: 0.3688 - accuracy: 0.8811\n",
      "Epoch 2/100\n",
      "216/216 [==============================] - 0s 910us/step - loss: 0.1669 - accuracy: 0.9489\n",
      "Epoch 3/100\n",
      "216/216 [==============================] - 0s 884us/step - loss: 0.1287 - accuracy: 0.9576\n",
      "Epoch 4/100\n",
      "216/216 [==============================] - 0s 742us/step - loss: 0.1181 - accuracy: 0.9619\n",
      "Epoch 5/100\n",
      "216/216 [==============================] - 0s 749us/step - loss: 0.1148 - accuracy: 0.9634\n",
      "Epoch 6/100\n",
      "216/216 [==============================] - 0s 861us/step - loss: 0.1135 - accuracy: 0.9640\n",
      "Epoch 7/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.9641\n",
      "Epoch 8/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1122 - accuracy: 0.9641\n",
      "Epoch 9/100\n",
      "216/216 [==============================] - 0s 741us/step - loss: 0.1118 - accuracy: 0.9643\n",
      "Epoch 10/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1113 - accuracy: 0.9644\n",
      "Epoch 11/100\n",
      "216/216 [==============================] - 0s 738us/step - loss: 0.1109 - accuracy: 0.9645\n",
      "Epoch 12/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1105 - accuracy: 0.9649\n",
      "Epoch 13/100\n",
      "216/216 [==============================] - 0s 764us/step - loss: 0.1101 - accuracy: 0.9647\n",
      "Epoch 14/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1097 - accuracy: 0.9650\n",
      "Epoch 15/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.1093 - accuracy: 0.9652\n",
      "Epoch 16/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1090 - accuracy: 0.9653\n",
      "Epoch 17/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1087 - accuracy: 0.9654\n",
      "Epoch 18/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1085 - accuracy: 0.9654\n",
      "Epoch 19/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.1084 - accuracy: 0.9656\n",
      "Epoch 20/100\n",
      "216/216 [==============================] - 0s 743us/step - loss: 0.1083 - accuracy: 0.9656\n",
      "Epoch 21/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1082 - accuracy: 0.9658\n",
      "Epoch 22/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1081 - accuracy: 0.9658\n",
      "Epoch 23/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1081 - accuracy: 0.9657\n",
      "Epoch 24/100\n",
      "216/216 [==============================] - 0s 753us/step - loss: 0.1080 - accuracy: 0.9658\n",
      "Epoch 25/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1079 - accuracy: 0.9659\n",
      "Epoch 26/100\n",
      "216/216 [==============================] - 0s 755us/step - loss: 0.1078 - accuracy: 0.9658\n",
      "Epoch 27/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1078 - accuracy: 0.9658\n",
      "Epoch 28/100\n",
      "216/216 [==============================] - 0s 713us/step - loss: 0.1077 - accuracy: 0.9660\n",
      "Epoch 29/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1077 - accuracy: 0.9659\n",
      "Epoch 30/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1077 - accuracy: 0.9658\n",
      "Epoch 31/100\n",
      "216/216 [==============================] - 0s 734us/step - loss: 0.1077 - accuracy: 0.9659\n",
      "Epoch 32/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1076 - accuracy: 0.9659\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 717us/step - loss: 0.1076 - accuracy: 0.9660\n",
      "Epoch 34/100\n",
      "216/216 [==============================] - 0s 710us/step - loss: 0.1075 - accuracy: 0.9660\n",
      "Epoch 35/100\n",
      "216/216 [==============================] - 0s 712us/step - loss: 0.1075 - accuracy: 0.9659\n",
      "Epoch 36/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1074 - accuracy: 0.9661\n",
      "Epoch 37/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1074 - accuracy: 0.9661\n",
      "Epoch 38/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1073 - accuracy: 0.9662\n",
      "Epoch 39/100\n",
      "216/216 [==============================] - 0s 721us/step - loss: 0.1073 - accuracy: 0.9661\n",
      "Epoch 40/100\n",
      "216/216 [==============================] - 0s 737us/step - loss: 0.1072 - accuracy: 0.9662\n",
      "Epoch 41/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1072 - accuracy: 0.9661\n",
      "Epoch 42/100\n",
      "216/216 [==============================] - 0s 713us/step - loss: 0.1071 - accuracy: 0.9663\n",
      "Epoch 43/100\n",
      "216/216 [==============================] - 0s 715us/step - loss: 0.1070 - accuracy: 0.9661\n",
      "Epoch 44/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1070 - accuracy: 0.9662\n",
      "Epoch 45/100\n",
      "216/216 [==============================] - 0s 722us/step - loss: 0.1069 - accuracy: 0.9663\n",
      "Epoch 46/100\n",
      "216/216 [==============================] - 0s 762us/step - loss: 0.1069 - accuracy: 0.9664\n",
      "Epoch 47/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1069 - accuracy: 0.9661\n",
      "Epoch 48/100\n",
      "216/216 [==============================] - 0s 709us/step - loss: 0.1068 - accuracy: 0.9662\n",
      "Epoch 49/100\n",
      "216/216 [==============================] - 0s 705us/step - loss: 0.1068 - accuracy: 0.9663\n",
      "Epoch 50/100\n",
      "216/216 [==============================] - 0s 711us/step - loss: 0.1067 - accuracy: 0.9663\n",
      "Epoch 51/100\n",
      "216/216 [==============================] - 0s 731us/step - loss: 0.1067 - accuracy: 0.9663\n",
      "Epoch 52/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1067 - accuracy: 0.9663\n",
      "Epoch 53/100\n",
      "216/216 [==============================] - 0s 715us/step - loss: 0.1066 - accuracy: 0.9662\n",
      "Epoch 54/100\n",
      "216/216 [==============================] - 0s 711us/step - loss: 0.1066 - accuracy: 0.9662\n",
      "Epoch 55/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1065 - accuracy: 0.9663\n",
      "Epoch 56/100\n",
      "216/216 [==============================] - 0s 710us/step - loss: 0.1065 - accuracy: 0.9661\n",
      "Epoch 57/100\n",
      "216/216 [==============================] - 0s 713us/step - loss: 0.1064 - accuracy: 0.9663\n",
      "Epoch 58/100\n",
      "216/216 [==============================] - 0s 748us/step - loss: 0.1063 - accuracy: 0.9664\n",
      "Epoch 59/100\n",
      "216/216 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9662\n",
      "Epoch 60/100\n",
      "216/216 [==============================] - 0s 826us/step - loss: 0.1063 - accuracy: 0.9665\n",
      "Epoch 61/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1062 - accuracy: 0.9663\n",
      "Epoch 62/100\n",
      "216/216 [==============================] - 0s 780us/step - loss: 0.1062 - accuracy: 0.9664\n",
      "Epoch 63/100\n",
      "216/216 [==============================] - 0s 712us/step - loss: 0.1062 - accuracy: 0.9663\n",
      "Epoch 64/100\n",
      "216/216 [==============================] - 0s 757us/step - loss: 0.1062 - accuracy: 0.9664\n",
      "Epoch 65/100\n",
      "216/216 [==============================] - 0s 824us/step - loss: 0.1061 - accuracy: 0.9664\n",
      "Epoch 66/100\n",
      "216/216 [==============================] - 0s 710us/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 67/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1061 - accuracy: 0.9664\n",
      "Epoch 68/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 69/100\n",
      "216/216 [==============================] - 0s 738us/step - loss: 0.1060 - accuracy: 0.9665\n",
      "Epoch 70/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1059 - accuracy: 0.9664\n",
      "Epoch 71/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1059 - accuracy: 0.9663\n",
      "Epoch 72/100\n",
      "216/216 [==============================] - 0s 765us/step - loss: 0.1059 - accuracy: 0.9664\n",
      "Epoch 73/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1059 - accuracy: 0.9666\n",
      "Epoch 74/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1058 - accuracy: 0.9664\n",
      "Epoch 75/100\n",
      "216/216 [==============================] - 0s 741us/step - loss: 0.1058 - accuracy: 0.9665\n",
      "Epoch 76/100\n",
      "216/216 [==============================] - 0s 743us/step - loss: 0.1058 - accuracy: 0.9665\n",
      "Epoch 77/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1057 - accuracy: 0.9666\n",
      "Epoch 78/100\n",
      "216/216 [==============================] - 0s 714us/step - loss: 0.1057 - accuracy: 0.9664\n",
      "Epoch 79/100\n",
      "216/216 [==============================] - 0s 712us/step - loss: 0.1057 - accuracy: 0.9665\n",
      "Epoch 80/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1057 - accuracy: 0.9665\n",
      "Epoch 81/100\n",
      "216/216 [==============================] - 0s 708us/step - loss: 0.1056 - accuracy: 0.9664\n",
      "Epoch 82/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1056 - accuracy: 0.9665\n",
      "Epoch 83/100\n",
      "216/216 [==============================] - 0s 721us/step - loss: 0.1056 - accuracy: 0.9665\n",
      "Epoch 84/100\n",
      "216/216 [==============================] - 0s 714us/step - loss: 0.1056 - accuracy: 0.9666\n",
      "Epoch 85/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1056 - accuracy: 0.9665\n",
      "Epoch 86/100\n",
      "216/216 [==============================] - 0s 743us/step - loss: 0.1055 - accuracy: 0.9665\n",
      "Epoch 87/100\n",
      "216/216 [==============================] - 0s 788us/step - loss: 0.1055 - accuracy: 0.9664\n",
      "Epoch 88/100\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.1055 - accuracy: 0.9664\n",
      "Epoch 89/100\n",
      "216/216 [==============================] - 0s 782us/step - loss: 0.1054 - accuracy: 0.9665\n",
      "Epoch 90/100\n",
      "216/216 [==============================] - 0s 752us/step - loss: 0.1055 - accuracy: 0.9664\n",
      "Epoch 91/100\n",
      "216/216 [==============================] - 0s 755us/step - loss: 0.1054 - accuracy: 0.9665\n",
      "Epoch 92/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1054 - accuracy: 0.9666\n",
      "Epoch 93/100\n",
      "216/216 [==============================] - 0s 754us/step - loss: 0.1054 - accuracy: 0.9666\n",
      "Epoch 94/100\n",
      "216/216 [==============================] - 0s 803us/step - loss: 0.1053 - accuracy: 0.9667\n",
      "Epoch 95/100\n",
      "216/216 [==============================] - 0s 754us/step - loss: 0.1053 - accuracy: 0.9665\n",
      "Epoch 96/100\n",
      "216/216 [==============================] - 0s 787us/step - loss: 0.1053 - accuracy: 0.9665\n",
      "Epoch 97/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1053 - accuracy: 0.9666\n",
      "Epoch 98/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1053 - accuracy: 0.9666\n",
      "Epoch 99/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1052 - accuracy: 0.9666\n",
      "Epoch 100/100\n",
      "216/216 [==============================] - 0s 847us/step - loss: 0.1052 - accuracy: 0.9665\n",
      "24/24 [==============================] - 0s 651us/step - loss: 0.1009 - accuracy: 0.9688\n",
      "Epoch 1/100\n",
      "216/216 [==============================] - 0s 757us/step - loss: 0.5963 - accuracy: 0.6853\n",
      "Epoch 2/100\n",
      "216/216 [==============================] - 0s 713us/step - loss: 0.2342 - accuracy: 0.9466\n",
      "Epoch 3/100\n",
      "216/216 [==============================] - 0s 706us/step - loss: 0.1638 - accuracy: 0.9491\n",
      "Epoch 4/100\n",
      "216/216 [==============================] - 0s 736us/step - loss: 0.1409 - accuracy: 0.9535\n",
      "Epoch 5/100\n",
      "216/216 [==============================] - 0s 782us/step - loss: 0.1296 - accuracy: 0.9576\n",
      "Epoch 6/100\n",
      "216/216 [==============================] - 0s 857us/step - loss: 0.1232 - accuracy: 0.9605\n",
      "Epoch 7/100\n",
      "216/216 [==============================] - 0s 781us/step - loss: 0.1193 - accuracy: 0.9620\n",
      "Epoch 8/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1170 - accuracy: 0.9629\n",
      "Epoch 9/100\n",
      "216/216 [==============================] - 0s 744us/step - loss: 0.1157 - accuracy: 0.9634\n",
      "Epoch 10/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1148 - accuracy: 0.9638\n",
      "Epoch 11/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1142 - accuracy: 0.9639\n",
      "Epoch 12/100\n",
      "216/216 [==============================] - 0s 740us/step - loss: 0.1136 - accuracy: 0.9642\n",
      "Epoch 13/100\n",
      "216/216 [==============================] - 0s 707us/step - loss: 0.1131 - accuracy: 0.9642\n",
      "Epoch 14/100\n",
      "216/216 [==============================] - 0s 714us/step - loss: 0.1126 - accuracy: 0.9644\n",
      "Epoch 15/100\n",
      "216/216 [==============================] - 0s 755us/step - loss: 0.1122 - accuracy: 0.9646\n",
      "Epoch 16/100\n",
      "216/216 [==============================] - 0s 776us/step - loss: 0.1118 - accuracy: 0.9647\n",
      "Epoch 17/100\n",
      "216/216 [==============================] - 0s 751us/step - loss: 0.1114 - accuracy: 0.9648\n",
      "Epoch 18/100\n",
      "216/216 [==============================] - 0s 705us/step - loss: 0.1110 - accuracy: 0.9648\n",
      "Epoch 19/100\n",
      "216/216 [==============================] - 0s 722us/step - loss: 0.1107 - accuracy: 0.9650\n",
      "Epoch 20/100\n",
      "216/216 [==============================] - 0s 713us/step - loss: 0.1104 - accuracy: 0.9650\n",
      "Epoch 21/100\n",
      "216/216 [==============================] - 0s 707us/step - loss: 0.1101 - accuracy: 0.9652\n",
      "Epoch 22/100\n",
      "216/216 [==============================] - 0s 813us/step - loss: 0.1098 - accuracy: 0.9654\n",
      "Epoch 23/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1097 - accuracy: 0.9653\n",
      "Epoch 24/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1095 - accuracy: 0.9653\n",
      "Epoch 25/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1093 - accuracy: 0.9653\n",
      "Epoch 26/100\n",
      "216/216 [==============================] - 0s 713us/step - loss: 0.1090 - accuracy: 0.9655\n",
      "Epoch 27/100\n",
      "216/216 [==============================] - 0s 707us/step - loss: 0.1088 - accuracy: 0.9655\n",
      "Epoch 28/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1087 - accuracy: 0.9655\n",
      "Epoch 29/100\n",
      "216/216 [==============================] - 0s 734us/step - loss: 0.1086 - accuracy: 0.9655\n",
      "Epoch 30/100\n",
      "216/216 [==============================] - 0s 711us/step - loss: 0.1084 - accuracy: 0.9656\n",
      "Epoch 31/100\n",
      "216/216 [==============================] - 0s 714us/step - loss: 0.1083 - accuracy: 0.9656\n",
      "Epoch 32/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1081 - accuracy: 0.9658\n",
      "Epoch 33/100\n",
      "216/216 [==============================] - 0s 762us/step - loss: 0.1080 - accuracy: 0.9657\n",
      "Epoch 34/100\n",
      "216/216 [==============================] - 0s 747us/step - loss: 0.1079 - accuracy: 0.9658\n",
      "Epoch 35/100\n",
      "216/216 [==============================] - 0s 760us/step - loss: 0.1078 - accuracy: 0.9657\n",
      "Epoch 36/100\n",
      "216/216 [==============================] - 0s 794us/step - loss: 0.1077 - accuracy: 0.9659\n",
      "Epoch 37/100\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.1076 - accuracy: 0.9659\n",
      "Epoch 38/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1075 - accuracy: 0.9659\n",
      "Epoch 39/100\n",
      "216/216 [==============================] - 0s 747us/step - loss: 0.1075 - accuracy: 0.9659\n",
      "Epoch 40/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1074 - accuracy: 0.9659\n",
      "Epoch 41/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1074 - accuracy: 0.9659\n",
      "Epoch 42/100\n",
      "216/216 [==============================] - 0s 771us/step - loss: 0.1073 - accuracy: 0.9659\n",
      "Epoch 43/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1072 - accuracy: 0.9660\n",
      "Epoch 44/100\n",
      "216/216 [==============================] - 0s 741us/step - loss: 0.1073 - accuracy: 0.9660\n",
      "Epoch 45/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1072 - accuracy: 0.9660\n",
      "Epoch 46/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1072 - accuracy: 0.9660\n",
      "Epoch 47/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1072 - accuracy: 0.9660\n",
      "Epoch 48/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1071 - accuracy: 0.9661\n",
      "Epoch 49/100\n",
      "216/216 [==============================] - 0s 821us/step - loss: 0.1071 - accuracy: 0.9660\n",
      "Epoch 50/100\n",
      "216/216 [==============================] - 0s 785us/step - loss: 0.1070 - accuracy: 0.9662\n",
      "Epoch 51/100\n",
      "216/216 [==============================] - 0s 771us/step - loss: 0.1071 - accuracy: 0.9661\n",
      "Epoch 52/100\n",
      "216/216 [==============================] - 0s 788us/step - loss: 0.1071 - accuracy: 0.9662\n",
      "Epoch 53/100\n",
      "216/216 [==============================] - 0s 824us/step - loss: 0.1070 - accuracy: 0.9661\n",
      "Epoch 54/100\n",
      "216/216 [==============================] - 0s 849us/step - loss: 0.1070 - accuracy: 0.9663\n",
      "Epoch 55/100\n",
      "216/216 [==============================] - 0s 907us/step - loss: 0.1070 - accuracy: 0.9661\n",
      "Epoch 56/100\n",
      "216/216 [==============================] - 0s 857us/step - loss: 0.1070 - accuracy: 0.9662\n",
      "Epoch 57/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1069 - accuracy: 0.9661\n",
      "Epoch 58/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1069 - accuracy: 0.9661\n",
      "Epoch 59/100\n",
      "216/216 [==============================] - 0s 776us/step - loss: 0.1069 - accuracy: 0.9661\n",
      "Epoch 60/100\n",
      "216/216 [==============================] - 0s 819us/step - loss: 0.1069 - accuracy: 0.9662\n",
      "Epoch 61/100\n",
      "216/216 [==============================] - 0s 758us/step - loss: 0.1069 - accuracy: 0.9660\n",
      "Epoch 62/100\n",
      "216/216 [==============================] - 0s 714us/step - loss: 0.1068 - accuracy: 0.9661\n",
      "Epoch 63/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1069 - accuracy: 0.9662\n",
      "Epoch 64/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1068 - accuracy: 0.9661\n",
      "Epoch 65/100\n",
      "216/216 [==============================] - 0s 742us/step - loss: 0.1068 - accuracy: 0.9661\n",
      "Epoch 66/100\n",
      "216/216 [==============================] - 0s 742us/step - loss: 0.1068 - accuracy: 0.9662\n",
      "Epoch 67/100\n",
      "216/216 [==============================] - 0s 714us/step - loss: 0.1067 - accuracy: 0.9662\n",
      "Epoch 68/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1067 - accuracy: 0.9662\n",
      "Epoch 69/100\n",
      "216/216 [==============================] - 0s 712us/step - loss: 0.1068 - accuracy: 0.9661\n",
      "Epoch 70/100\n",
      "216/216 [==============================] - 0s 745us/step - loss: 0.1067 - accuracy: 0.9661\n",
      "Epoch 71/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1067 - accuracy: 0.9662\n",
      "Epoch 72/100\n",
      "216/216 [==============================] - 0s 740us/step - loss: 0.1067 - accuracy: 0.9661\n",
      "Epoch 73/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1066 - accuracy: 0.9661\n",
      "Epoch 74/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1066 - accuracy: 0.9662\n",
      "Epoch 75/100\n",
      "216/216 [==============================] - 0s 738us/step - loss: 0.1066 - accuracy: 0.9661\n",
      "Epoch 76/100\n",
      "216/216 [==============================] - 0s 710us/step - loss: 0.1066 - accuracy: 0.9660\n",
      "Epoch 77/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1066 - accuracy: 0.9660\n",
      "Epoch 78/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1066 - accuracy: 0.9661\n",
      "Epoch 79/100\n",
      "216/216 [==============================] - 0s 736us/step - loss: 0.1066 - accuracy: 0.9660\n",
      "Epoch 80/100\n",
      "216/216 [==============================] - 0s 739us/step - loss: 0.1066 - accuracy: 0.9662\n",
      "Epoch 81/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1064 - accuracy: 0.9661\n",
      "Epoch 82/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1065 - accuracy: 0.9661\n",
      "Epoch 83/100\n",
      "216/216 [==============================] - 0s 735us/step - loss: 0.1064 - accuracy: 0.9663\n",
      "Epoch 84/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1063 - accuracy: 0.9664\n",
      "Epoch 85/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1062 - accuracy: 0.9664\n",
      "Epoch 86/100\n",
      "216/216 [==============================] - 0s 711us/step - loss: 0.1062 - accuracy: 0.9664\n",
      "Epoch 87/100\n",
      "216/216 [==============================] - 0s 737us/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 88/100\n",
      "216/216 [==============================] - 0s 749us/step - loss: 0.1060 - accuracy: 0.9665\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 759us/step - loss: 0.1059 - accuracy: 0.9666\n",
      "Epoch 90/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1058 - accuracy: 0.9665\n",
      "Epoch 91/100\n",
      "216/216 [==============================] - 0s 736us/step - loss: 0.1058 - accuracy: 0.9666\n",
      "Epoch 92/100\n",
      "216/216 [==============================] - 0s 731us/step - loss: 0.1057 - accuracy: 0.9665\n",
      "Epoch 93/100\n",
      "216/216 [==============================] - 0s 760us/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 94/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1056 - accuracy: 0.9668\n",
      "Epoch 95/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1055 - accuracy: 0.9667\n",
      "Epoch 96/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1054 - accuracy: 0.9667\n",
      "Epoch 97/100\n",
      "216/216 [==============================] - 0s 759us/step - loss: 0.1054 - accuracy: 0.9667\n",
      "Epoch 98/100\n",
      "216/216 [==============================] - 0s 742us/step - loss: 0.1053 - accuracy: 0.9668\n",
      "Epoch 99/100\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.1053 - accuracy: 0.9669\n",
      "Epoch 100/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1053 - accuracy: 0.9668\n",
      "24/24 [==============================] - 0s 689us/step - loss: 0.1011 - accuracy: 0.9675\n",
      "Epoch 1/100\n",
      "216/216 [==============================] - 0s 750us/step - loss: 0.5410 - accuracy: 0.7678\n",
      "Epoch 2/100\n",
      "216/216 [==============================] - 0s 745us/step - loss: 0.2322 - accuracy: 0.9392\n",
      "Epoch 3/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1647 - accuracy: 0.9505\n",
      "Epoch 4/100\n",
      "216/216 [==============================] - 0s 721us/step - loss: 0.1430 - accuracy: 0.9544\n",
      "Epoch 5/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1324 - accuracy: 0.9573\n",
      "Epoch 6/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1259 - accuracy: 0.9595\n",
      "Epoch 7/100\n",
      "216/216 [==============================] - 0s 745us/step - loss: 0.1217 - accuracy: 0.9612\n",
      "Epoch 8/100\n",
      "216/216 [==============================] - 0s 711us/step - loss: 0.1187 - accuracy: 0.9622\n",
      "Epoch 9/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1165 - accuracy: 0.9630\n",
      "Epoch 10/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1149 - accuracy: 0.9636\n",
      "Epoch 11/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1137 - accuracy: 0.9638\n",
      "Epoch 12/100\n",
      "216/216 [==============================] - 0s 737us/step - loss: 0.1128 - accuracy: 0.9641\n",
      "Epoch 13/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1120 - accuracy: 0.9643\n",
      "Epoch 14/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1114 - accuracy: 0.9644\n",
      "Epoch 15/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1108 - accuracy: 0.9647\n",
      "Epoch 16/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1102 - accuracy: 0.9646\n",
      "Epoch 17/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1096 - accuracy: 0.9651\n",
      "Epoch 18/100\n",
      "216/216 [==============================] - 0s 721us/step - loss: 0.1091 - accuracy: 0.9651\n",
      "Epoch 19/100\n",
      "216/216 [==============================] - 0s 741us/step - loss: 0.1086 - accuracy: 0.9653\n",
      "Epoch 20/100\n",
      "216/216 [==============================] - 0s 748us/step - loss: 0.1081 - accuracy: 0.9653\n",
      "Epoch 21/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1076 - accuracy: 0.9656\n",
      "Epoch 22/100\n",
      "216/216 [==============================] - 0s 734us/step - loss: 0.1073 - accuracy: 0.9657\n",
      "Epoch 23/100\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.1070 - accuracy: 0.9658\n",
      "Epoch 24/100\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.1068 - accuracy: 0.9660\n",
      "Epoch 25/100\n",
      "216/216 [==============================] - 0s 699us/step - loss: 0.1066 - accuracy: 0.9660\n",
      "Epoch 26/100\n",
      "216/216 [==============================] - 0s 731us/step - loss: 0.1063 - accuracy: 0.9662\n",
      "Epoch 27/100\n",
      "216/216 [==============================] - 0s 767us/step - loss: 0.1062 - accuracy: 0.9660\n",
      "Epoch 28/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1061 - accuracy: 0.9662\n",
      "Epoch 29/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1059 - accuracy: 0.9661\n",
      "Epoch 30/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1058 - accuracy: 0.9662\n",
      "Epoch 31/100\n",
      "216/216 [==============================] - 0s 840us/step - loss: 0.1056 - accuracy: 0.9663\n",
      "Epoch 32/100\n",
      "216/216 [==============================] - 0s 811us/step - loss: 0.1055 - accuracy: 0.9663\n",
      "Epoch 33/100\n",
      "216/216 [==============================] - 0s 737us/step - loss: 0.1053 - accuracy: 0.9662\n",
      "Epoch 34/100\n",
      "216/216 [==============================] - 0s 715us/step - loss: 0.1053 - accuracy: 0.9664\n",
      "Epoch 35/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1051 - accuracy: 0.9663\n",
      "Epoch 36/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1050 - accuracy: 0.9664\n",
      "Epoch 37/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1049 - accuracy: 0.9664\n",
      "Epoch 38/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1048 - accuracy: 0.9664\n",
      "Epoch 39/100\n",
      "216/216 [==============================] - 0s 791us/step - loss: 0.1047 - accuracy: 0.9665\n",
      "Epoch 40/100\n",
      "216/216 [==============================] - 0s 762us/step - loss: 0.1046 - accuracy: 0.9665\n",
      "Epoch 41/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1045 - accuracy: 0.9665\n",
      "Epoch 42/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.1044 - accuracy: 0.9666\n",
      "Epoch 43/100\n",
      "216/216 [==============================] - 0s 761us/step - loss: 0.1044 - accuracy: 0.9667\n",
      "Epoch 44/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1043 - accuracy: 0.9664\n",
      "Epoch 45/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1042 - accuracy: 0.9666\n",
      "Epoch 46/100\n",
      "216/216 [==============================] - 0s 739us/step - loss: 0.1042 - accuracy: 0.9666\n",
      "Epoch 47/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1041 - accuracy: 0.9666\n",
      "Epoch 48/100\n",
      "216/216 [==============================] - 0s 713us/step - loss: 0.1040 - accuracy: 0.9666\n",
      "Epoch 49/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1040 - accuracy: 0.9667\n",
      "Epoch 50/100\n",
      "216/216 [==============================] - 0s 745us/step - loss: 0.1040 - accuracy: 0.9668\n",
      "Epoch 51/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1039 - accuracy: 0.9668\n",
      "Epoch 52/100\n",
      "216/216 [==============================] - 0s 754us/step - loss: 0.1039 - accuracy: 0.9667\n",
      "Epoch 53/100\n",
      "216/216 [==============================] - 0s 771us/step - loss: 0.1038 - accuracy: 0.9667\n",
      "Epoch 54/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1038 - accuracy: 0.9667\n",
      "Epoch 55/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1038 - accuracy: 0.9668\n",
      "Epoch 56/100\n",
      "216/216 [==============================] - 0s 740us/step - loss: 0.1037 - accuracy: 0.9668\n",
      "Epoch 57/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1037 - accuracy: 0.9668\n",
      "Epoch 58/100\n",
      "216/216 [==============================] - 0s 722us/step - loss: 0.1036 - accuracy: 0.9668\n",
      "Epoch 59/100\n",
      "216/216 [==============================] - 0s 714us/step - loss: 0.1036 - accuracy: 0.9670\n",
      "Epoch 60/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1036 - accuracy: 0.9668\n",
      "Epoch 61/100\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.1036 - accuracy: 0.9667\n",
      "Epoch 62/100\n",
      "216/216 [==============================] - 0s 734us/step - loss: 0.1036 - accuracy: 0.9669\n",
      "Epoch 63/100\n",
      "216/216 [==============================] - 0s 708us/step - loss: 0.1035 - accuracy: 0.9669\n",
      "Epoch 64/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1035 - accuracy: 0.9669\n",
      "Epoch 65/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1035 - accuracy: 0.9668\n",
      "Epoch 66/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1035 - accuracy: 0.9669\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 724us/step - loss: 0.1034 - accuracy: 0.9668\n",
      "Epoch 68/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1034 - accuracy: 0.9669\n",
      "Epoch 69/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1035 - accuracy: 0.9671\n",
      "Epoch 70/100\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.1034 - accuracy: 0.9669\n",
      "Epoch 71/100\n",
      "216/216 [==============================] - 0s 722us/step - loss: 0.1034 - accuracy: 0.9669\n",
      "Epoch 72/100\n",
      "216/216 [==============================] - 0s 742us/step - loss: 0.1034 - accuracy: 0.9670\n",
      "Epoch 73/100\n",
      "216/216 [==============================] - 0s 708us/step - loss: 0.1033 - accuracy: 0.9669\n",
      "Epoch 74/100\n",
      "216/216 [==============================] - 0s 738us/step - loss: 0.1033 - accuracy: 0.9671\n",
      "Epoch 75/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1033 - accuracy: 0.9668\n",
      "Epoch 76/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1034 - accuracy: 0.9668\n",
      "Epoch 77/100\n",
      "216/216 [==============================] - 0s 707us/step - loss: 0.1033 - accuracy: 0.9670\n",
      "Epoch 78/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1033 - accuracy: 0.9670\n",
      "Epoch 79/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.1033 - accuracy: 0.9669\n",
      "Epoch 80/100\n",
      "216/216 [==============================] - 0s 712us/step - loss: 0.1033 - accuracy: 0.9669\n",
      "Epoch 81/100\n",
      "216/216 [==============================] - 0s 734us/step - loss: 0.1033 - accuracy: 0.9669\n",
      "Epoch 82/100\n",
      "216/216 [==============================] - 0s 739us/step - loss: 0.1033 - accuracy: 0.9672\n",
      "Epoch 83/100\n",
      "216/216 [==============================] - 0s 722us/step - loss: 0.1033 - accuracy: 0.9669\n",
      "Epoch 84/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.1032 - accuracy: 0.9669\n",
      "Epoch 85/100\n",
      "216/216 [==============================] - 0s 745us/step - loss: 0.1032 - accuracy: 0.9670\n",
      "Epoch 86/100\n",
      "216/216 [==============================] - 0s 712us/step - loss: 0.1032 - accuracy: 0.9670\n",
      "Epoch 87/100\n",
      "216/216 [==============================] - 0s 736us/step - loss: 0.1032 - accuracy: 0.9669\n",
      "Epoch 88/100\n",
      "216/216 [==============================] - 0s 715us/step - loss: 0.1032 - accuracy: 0.9669\n",
      "Epoch 89/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1032 - accuracy: 0.9670\n",
      "Epoch 90/100\n",
      "216/216 [==============================] - 0s 737us/step - loss: 0.1032 - accuracy: 0.9671\n",
      "Epoch 91/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1032 - accuracy: 0.9669\n",
      "Epoch 92/100\n",
      "216/216 [==============================] - 0s 710us/step - loss: 0.1032 - accuracy: 0.9669\n",
      "Epoch 93/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1032 - accuracy: 0.9669\n",
      "Epoch 94/100\n",
      "216/216 [==============================] - 0s 758us/step - loss: 0.1032 - accuracy: 0.9670\n",
      "Epoch 95/100\n",
      "216/216 [==============================] - 0s 795us/step - loss: 0.1032 - accuracy: 0.9671\n",
      "Epoch 96/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1031 - accuracy: 0.9670\n",
      "Epoch 97/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1032 - accuracy: 0.9670\n",
      "Epoch 98/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1031 - accuracy: 0.9671\n",
      "Epoch 99/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1031 - accuracy: 0.9670\n",
      "Epoch 100/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1031 - accuracy: 0.9669\n",
      "24/24 [==============================] - 0s 686us/step - loss: 0.1124 - accuracy: 0.9657\n",
      "Epoch 1/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.6869 - accuracy: 0.5979\n",
      "Epoch 2/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.2559 - accuracy: 0.9424\n",
      "Epoch 3/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1623 - accuracy: 0.9543\n",
      "Epoch 4/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1364 - accuracy: 0.9587\n",
      "Epoch 5/100\n",
      "216/216 [==============================] - 0s 710us/step - loss: 0.1255 - accuracy: 0.9611\n",
      "Epoch 6/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1200 - accuracy: 0.9620\n",
      "Epoch 7/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1169 - accuracy: 0.9631\n",
      "Epoch 8/100\n",
      "216/216 [==============================] - 0s 703us/step - loss: 0.1150 - accuracy: 0.9635\n",
      "Epoch 9/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1137 - accuracy: 0.9637\n",
      "Epoch 10/100\n",
      "216/216 [==============================] - 0s 703us/step - loss: 0.1128 - accuracy: 0.9641\n",
      "Epoch 11/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1120 - accuracy: 0.9643\n",
      "Epoch 12/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1113 - accuracy: 0.9645\n",
      "Epoch 13/100\n",
      "216/216 [==============================] - 0s 700us/step - loss: 0.1106 - accuracy: 0.9649\n",
      "Epoch 14/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1100 - accuracy: 0.9652\n",
      "Epoch 15/100\n",
      "216/216 [==============================] - 0s 705us/step - loss: 0.1095 - accuracy: 0.9652\n",
      "Epoch 16/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1091 - accuracy: 0.9655\n",
      "Epoch 17/100\n",
      "216/216 [==============================] - 0s 741us/step - loss: 0.1087 - accuracy: 0.9655\n",
      "Epoch 18/100\n",
      "216/216 [==============================] - 0s 702us/step - loss: 0.1084 - accuracy: 0.9657\n",
      "Epoch 19/100\n",
      "216/216 [==============================] - 0s 725us/step - loss: 0.1081 - accuracy: 0.9658\n",
      "Epoch 20/100\n",
      "216/216 [==============================] - 0s 732us/step - loss: 0.1079 - accuracy: 0.9658\n",
      "Epoch 21/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1077 - accuracy: 0.9658\n",
      "Epoch 22/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1076 - accuracy: 0.9658\n",
      "Epoch 23/100\n",
      "216/216 [==============================] - 0s 788us/step - loss: 0.1075 - accuracy: 0.9662\n",
      "Epoch 24/100\n",
      "216/216 [==============================] - 0s 795us/step - loss: 0.1074 - accuracy: 0.9660\n",
      "Epoch 25/100\n",
      "216/216 [==============================] - 0s 715us/step - loss: 0.1073 - accuracy: 0.9660\n",
      "Epoch 26/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1073 - accuracy: 0.9660\n",
      "Epoch 27/100\n",
      "216/216 [==============================] - 0s 722us/step - loss: 0.1072 - accuracy: 0.9660\n",
      "Epoch 28/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1071 - accuracy: 0.9661\n",
      "Epoch 29/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1071 - accuracy: 0.9661\n",
      "Epoch 30/100\n",
      "216/216 [==============================] - 0s 753us/step - loss: 0.1070 - accuracy: 0.9662\n",
      "Epoch 31/100\n",
      "216/216 [==============================] - 0s 751us/step - loss: 0.1070 - accuracy: 0.9663\n",
      "Epoch 32/100\n",
      "216/216 [==============================] - 0s 715us/step - loss: 0.1069 - accuracy: 0.9661\n",
      "Epoch 33/100\n",
      "216/216 [==============================] - 0s 698us/step - loss: 0.1069 - accuracy: 0.9662\n",
      "Epoch 34/100\n",
      "216/216 [==============================] - 0s 739us/step - loss: 0.1069 - accuracy: 0.9660\n",
      "Epoch 35/100\n",
      "216/216 [==============================] - 0s 708us/step - loss: 0.1068 - accuracy: 0.9662\n",
      "Epoch 36/100\n",
      "216/216 [==============================] - 0s 748us/step - loss: 0.1068 - accuracy: 0.9662\n",
      "Epoch 37/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1068 - accuracy: 0.9662\n",
      "Epoch 38/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1067 - accuracy: 0.9663\n",
      "Epoch 39/100\n",
      "216/216 [==============================] - 0s 738us/step - loss: 0.1066 - accuracy: 0.9663\n",
      "Epoch 40/100\n",
      "216/216 [==============================] - 0s 698us/step - loss: 0.1066 - accuracy: 0.9663\n",
      "Epoch 41/100\n",
      "216/216 [==============================] - 0s 708us/step - loss: 0.1066 - accuracy: 0.9662\n",
      "Epoch 42/100\n",
      "216/216 [==============================] - 0s 722us/step - loss: 0.1065 - accuracy: 0.9663\n",
      "Epoch 43/100\n",
      "216/216 [==============================] - 0s 714us/step - loss: 0.1065 - accuracy: 0.9663\n",
      "Epoch 44/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1065 - accuracy: 0.9664\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 0s 716us/step - loss: 0.1065 - accuracy: 0.9662\n",
      "Epoch 46/100\n",
      "216/216 [==============================] - 0s 715us/step - loss: 0.1064 - accuracy: 0.9663\n",
      "Epoch 47/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1064 - accuracy: 0.9663\n",
      "Epoch 48/100\n",
      "216/216 [==============================] - 0s 706us/step - loss: 0.1064 - accuracy: 0.9665\n",
      "Epoch 49/100\n",
      "216/216 [==============================] - 0s 721us/step - loss: 0.1063 - accuracy: 0.9663\n",
      "Epoch 50/100\n",
      "216/216 [==============================] - 0s 715us/step - loss: 0.1063 - accuracy: 0.9663\n",
      "Epoch 51/100\n",
      "216/216 [==============================] - 0s 698us/step - loss: 0.1063 - accuracy: 0.9666\n",
      "Epoch 52/100\n",
      "216/216 [==============================] - 0s 704us/step - loss: 0.1063 - accuracy: 0.9664\n",
      "Epoch 53/100\n",
      "216/216 [==============================] - 0s 722us/step - loss: 0.1062 - accuracy: 0.9664\n",
      "Epoch 54/100\n",
      "216/216 [==============================] - 0s 730us/step - loss: 0.1062 - accuracy: 0.9664\n",
      "Epoch 55/100\n",
      "216/216 [==============================] - 0s 711us/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 56/100\n",
      "216/216 [==============================] - 0s 694us/step - loss: 0.1061 - accuracy: 0.9663\n",
      "Epoch 57/100\n",
      "216/216 [==============================] - 0s 712us/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 58/100\n",
      "216/216 [==============================] - 0s 701us/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 59/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1060 - accuracy: 0.9665\n",
      "Epoch 60/100\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.1060 - accuracy: 0.9662\n",
      "Epoch 61/100\n",
      "216/216 [==============================] - 0s 713us/step - loss: 0.1060 - accuracy: 0.9663\n",
      "Epoch 62/100\n",
      "216/216 [==============================] - 0s 705us/step - loss: 0.1060 - accuracy: 0.9666\n",
      "Epoch 63/100\n",
      "216/216 [==============================] - 0s 702us/step - loss: 0.1060 - accuracy: 0.9665\n",
      "Epoch 64/100\n",
      "216/216 [==============================] - 0s 715us/step - loss: 0.1059 - accuracy: 0.9664\n",
      "Epoch 65/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1059 - accuracy: 0.9665\n",
      "Epoch 66/100\n",
      "216/216 [==============================] - 0s 714us/step - loss: 0.1059 - accuracy: 0.9664\n",
      "Epoch 67/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1058 - accuracy: 0.9664\n",
      "Epoch 68/100\n",
      "216/216 [==============================] - 0s 747us/step - loss: 0.1059 - accuracy: 0.9664\n",
      "Epoch 69/100\n",
      "216/216 [==============================] - 0s 707us/step - loss: 0.1059 - accuracy: 0.9665\n",
      "Epoch 70/100\n",
      "216/216 [==============================] - 0s 728us/step - loss: 0.1058 - accuracy: 0.9665\n",
      "Epoch 71/100\n",
      "216/216 [==============================] - 0s 751us/step - loss: 0.1059 - accuracy: 0.9665\n",
      "Epoch 72/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1058 - accuracy: 0.9664\n",
      "Epoch 73/100\n",
      "216/216 [==============================] - 0s 753us/step - loss: 0.1058 - accuracy: 0.9665\n",
      "Epoch 74/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1058 - accuracy: 0.9664\n",
      "Epoch 75/100\n",
      "216/216 [==============================] - 0s 764us/step - loss: 0.1058 - accuracy: 0.9666\n",
      "Epoch 76/100\n",
      "216/216 [==============================] - 0s 721us/step - loss: 0.1057 - accuracy: 0.9664\n",
      "Epoch 77/100\n",
      "216/216 [==============================] - 0s 727us/step - loss: 0.1058 - accuracy: 0.9665\n",
      "Epoch 78/100\n",
      "216/216 [==============================] - 0s 718us/step - loss: 0.1057 - accuracy: 0.9665\n",
      "Epoch 79/100\n",
      "216/216 [==============================] - 0s 798us/step - loss: 0.1057 - accuracy: 0.9664\n",
      "Epoch 80/100\n",
      "216/216 [==============================] - 0s 726us/step - loss: 0.1057 - accuracy: 0.9667\n",
      "Epoch 81/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1057 - accuracy: 0.9665\n",
      "Epoch 82/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1057 - accuracy: 0.9665\n",
      "Epoch 83/100\n",
      "216/216 [==============================] - 0s 705us/step - loss: 0.1056 - accuracy: 0.9664\n",
      "Epoch 84/100\n",
      "216/216 [==============================] - 0s 705us/step - loss: 0.1057 - accuracy: 0.9665\n",
      "Epoch 85/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1056 - accuracy: 0.9666\n",
      "Epoch 86/100\n",
      "216/216 [==============================] - 0s 722us/step - loss: 0.1056 - accuracy: 0.9665\n",
      "Epoch 87/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1056 - accuracy: 0.9666\n",
      "Epoch 88/100\n",
      "216/216 [==============================] - 0s 717us/step - loss: 0.1056 - accuracy: 0.9664\n",
      "Epoch 89/100\n",
      "216/216 [==============================] - 0s 729us/step - loss: 0.1056 - accuracy: 0.9665\n",
      "Epoch 90/100\n",
      "216/216 [==============================] - 0s 740us/step - loss: 0.1056 - accuracy: 0.9664\n",
      "Epoch 91/100\n",
      "216/216 [==============================] - 0s 723us/step - loss: 0.1056 - accuracy: 0.9665\n",
      "Epoch 92/100\n",
      "216/216 [==============================] - 0s 733us/step - loss: 0.1056 - accuracy: 0.9664\n",
      "Epoch 93/100\n",
      "216/216 [==============================] - 0s 784us/step - loss: 0.1055 - accuracy: 0.9666\n",
      "Epoch 94/100\n",
      "216/216 [==============================] - 0s 720us/step - loss: 0.1056 - accuracy: 0.9666\n",
      "Epoch 95/100\n",
      "216/216 [==============================] - 0s 719us/step - loss: 0.1056 - accuracy: 0.9665\n",
      "Epoch 96/100\n",
      "216/216 [==============================] - 0s 705us/step - loss: 0.1055 - accuracy: 0.9665\n",
      "Epoch 97/100\n",
      "216/216 [==============================] - 0s 716us/step - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 98/100\n",
      "216/216 [==============================] - 0s 724us/step - loss: 0.1055 - accuracy: 0.9665\n",
      "Epoch 99/100\n",
      "216/216 [==============================] - 0s 739us/step - loss: 0.1055 - accuracy: 0.9667\n",
      "Epoch 100/100\n",
      "216/216 [==============================] - 0s 709us/step - loss: 0.1055 - accuracy: 0.9664\n",
      "24/24 [==============================] - 0s 703us/step - loss: 0.1144 - accuracy: 0.9643\n",
      "Baseline: 96.68% (0.17%)\n"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #first layer is same as number of input variables\n",
    "    model.add(Dense(10, input_dim=10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=500, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X_train_scaled, y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot: test set error rate vs epochs\n",
    "#neural network validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
